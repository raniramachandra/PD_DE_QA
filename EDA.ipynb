{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2898cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "696d1f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Id                                     Books Book checkout Book Returned  \\\n",
      "0  1.0                       Catcher in the Rye   \"20/02/2023\"    25/02/2023   \n",
      "1  2.0          Lord of the rings the two towers  \"24/03/2023\"    21/03/2023   \n",
      "2  3.0  Lord of the rings the return of the kind  \"29/03/2023\"    25/03/2023   \n",
      "3  4.0                                The hobbit  \"02/04/2023\"    25/03/2023   \n",
      "4  5.0                                     Dune   \"02/04/2023\"    25/03/2023   \n",
      "\n",
      "  Days allowed to borrow  Customer ID  \n",
      "0                2 weeks          1.0  \n",
      "1                2 weeks          2.0  \n",
      "2                2 weeks          3.0  \n",
      "3                2 weeks          4.0  \n",
      "4                2 weeks          5.0  \n"
     ]
    }
   ],
   "source": [
    "file_path = '03_Library Systembook.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3238d376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id                        float64\n",
      "Books                      object\n",
      "Book checkout              object\n",
      "Book Returned              object\n",
      "Days allowed to borrow     object\n",
      "Customer ID               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fcfe46d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#can strip the extra quotes using str.replace() or str.strip() before converting:\n",
    "df['Book checkout'] = df['Book checkout'].str.replace('\"', '', regex=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39bc52e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Id                                     Books Book checkout  \\\n",
      "0    1.0                       Catcher in the Rye     20/02/2023   \n",
      "1    2.0          Lord of the rings the two towers    24/03/2023   \n",
      "2    3.0  Lord of the rings the return of the kind    29/03/2023   \n",
      "3    4.0                                The hobbit    02/04/2023   \n",
      "4    5.0                                     Dune     02/04/2023   \n",
      "..   ...                                       ...           ...   \n",
      "109  NaN                                       NaN           NaN   \n",
      "110  NaN                                       NaN           NaN   \n",
      "111  NaN                                       NaN           NaN   \n",
      "112  NaN                                       NaN           NaN   \n",
      "113  NaN                                       NaN           NaN   \n",
      "\n",
      "    Book Returned Days allowed to borrow  Customer ID  \n",
      "0      25/02/2023                2 weeks          1.0  \n",
      "1      21/03/2023                2 weeks          2.0  \n",
      "2      25/03/2023                2 weeks          3.0  \n",
      "3      25/03/2023                2 weeks          4.0  \n",
      "4      25/03/2023                2 weeks          5.0  \n",
      "..            ...                    ...          ...  \n",
      "109           NaN                    NaN          NaN  \n",
      "110           NaN                    NaN          NaN  \n",
      "111           NaN                    NaN          NaN  \n",
      "112           NaN                    NaN          NaN  \n",
      "113           NaN                    NaN          NaN  \n",
      "\n",
      "[114 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a89d0845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "\n",
    "# Global list to store logs of fixed dates (to be printed later)\n",
    "fixed_rows = []\n",
    "\n",
    "def fix_invalid_date(date_str):\n",
    "    # Skip NaN or invalid types\n",
    "    if pd.isna(date_str) or not isinstance(date_str, str):\n",
    "        return pd.NaT\n",
    "\n",
    "    try:\n",
    "        # Try to parse the date normally\n",
    "        return datetime.strptime(date_str, \"%d/%m/%Y\")\n",
    "    except ValueError:\n",
    "        # Handle invalid dates like 32/05/2023\n",
    "        try:\n",
    "            day, month, year = map(int, date_str.split('/'))\n",
    "            # Get the last valid day for the given month/year\n",
    "            last_day = calendar.monthrange(year, month)[1]\n",
    "            # Use last valid day if day is invalid\n",
    "            if day > last_day:\n",
    "                # Log the original and corrected date\n",
    "                fixed_rows.append((date_str, f\"{last_day}/{month}/{year}\"))\n",
    "                day = last_day\n",
    "            return datetime(year, month, day)\n",
    "        except Exception:\n",
    "            # If still invalid, return NaT\n",
    "            return pd.NaT\n",
    "\n",
    "# Function to clean and fix the date column in the DataFrame\n",
    "def clean_and_fix_dates(df, column_name):\n",
    "    # Apply the date fixing function to the column\n",
    "    df[column_name] = df[column_name].apply(fix_invalid_date)\n",
    "    \n",
    "    # Print log of fixed rows\n",
    "    if fixed_rows:\n",
    "        print(\"The following dates were fixed:\")\n",
    "        for old_date, new_date in fixed_rows:\n",
    "            print(f\"Fixed: {old_date} -> {new_date}\")\n",
    "    else:\n",
    "        print(\"No invalid dates were found.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# df = pd.read_csv('your_data.csv')  # Load your dataframe\n",
    "# df = clean_and_fix_dates(df, 'book checkout')\n",
    "\n",
    "# To check the cleaned DataFrame and the logs\n",
    "# print(df.head())\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# df = pd.read_csv('your_data.csv')  # Load your dataframe\n",
    "# df = clean_and_fix_dates(df, 'book checkout')\n",
    "\n",
    "# To check the cleaned DataFrame and the logs\n",
    "# print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db847cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id                        float64\n",
      "Books                      object\n",
      "Book checkout              object\n",
      "Book Returned              object\n",
      "Days allowed to borrow     object\n",
      "Customer ID               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34dd58b",
   "metadata": {},
   "source": [
    "Explanation of Changes:\n",
    "\n",
    "pd.isna(date_str): This checks if the value is NaN (not a number). If the date is missing or invalid (e.g., NaN), we return NaT (Not a Time).\n",
    "\n",
    "not isinstance(date_str, str): This checks if the value is a string before attempting to parse it. If it's not a string (for example, a float), we simply skip parsing and return NaT.\n",
    "\n",
    "NaT: This ensures that invalid or missing dates are handled gracefully.\n",
    "\n",
    "How it Works:\n",
    "\n",
    "The function will now handle NaN or missing values in the book checkout column and will not attempt to parse them.\n",
    "\n",
    "If the value is valid, it will be converted to a datetime.\n",
    "\n",
    "Invalid values like \"32/05/2023\" will be fixed to \"31/05/2023\", and these fixes will be logged.\n",
    "\n",
    "If the column contains non-date values or invalid types (like float), they will be skipped and marked as NaT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dbaa44d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following dates were fixed:\n",
      "Fixed: 32/05/2023 -> 31/5/2023\n",
      "    Id                                     Books Book checkout Book Returned  \\\n",
      "0  1.0                       Catcher in the Rye     2023-02-20    25/02/2023   \n",
      "1  2.0          Lord of the rings the two towers    2023-03-24    21/03/2023   \n",
      "2  3.0  Lord of the rings the return of the kind    2023-03-29    25/03/2023   \n",
      "3  4.0                                The hobbit    2023-04-02    25/03/2023   \n",
      "4  5.0                                     Dune     2023-04-02    25/03/2023   \n",
      "\n",
      "  Days allowed to borrow  Customer ID  \n",
      "0                2 weeks          1.0  \n",
      "1                2 weeks          2.0  \n",
      "2                2 weeks          3.0  \n",
      "3                2 weeks          4.0  \n",
      "4                2 weeks          5.0  \n"
     ]
    }
   ],
   "source": [
    "df = clean_and_fix_dates(df, 'Book checkout')\n",
    "# To check the cleaned DataFrame and the logs\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7a7026e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#can strip the extra quotes using str.replace() or str.strip() before converting:\n",
    "df['Book Returned'] = df['Book Returned'].str.replace('\"', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e3f74d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following dates were fixed:\n",
      "Fixed: 32/05/2023 -> 31/5/2023\n",
      "    Id                                     Books Book checkout Book Returned  \\\n",
      "0  1.0                       Catcher in the Rye     2023-02-20    2023-02-25   \n",
      "1  2.0          Lord of the rings the two towers    2023-03-24    2023-03-21   \n",
      "2  3.0  Lord of the rings the return of the kind    2023-03-29    2023-03-25   \n",
      "3  4.0                                The hobbit    2023-04-02    2023-03-25   \n",
      "4  5.0                                     Dune     2023-04-02    2023-03-25   \n",
      "\n",
      "  Days allowed to borrow  Customer ID  \n",
      "0                2 weeks          1.0  \n",
      "1                2 weeks          2.0  \n",
      "2                2 weeks          3.0  \n",
      "3                2 weeks          4.0  \n",
      "4                2 weeks          5.0  \n"
     ]
    }
   ],
   "source": [
    "df = clean_and_fix_dates(df, 'Book Returned')\n",
    "# To check the cleaned DataFrame and the logs\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "abda20c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned DataFrame:\n",
      "     Id                                     Books Book checkout Book Returned  \\\n",
      "0  1.0                       Catcher in the Rye     2023-02-20    2023-02-25   \n",
      "1  2.0          Lord of the rings the two towers    2023-03-24    2023-03-21   \n",
      "2  3.0  Lord of the rings the return of the kind    2023-03-29    2023-03-25   \n",
      "3  4.0                                The hobbit    2023-04-02    2023-03-25   \n",
      "4  5.0                                     Dune     2023-04-02    2023-03-25   \n",
      "\n",
      "  Days allowed to borrow  Customer ID  \n",
      "0                2 weeks          1.0  \n",
      "1                2 weeks          2.0  \n",
      "2                2 weeks          3.0  \n",
      "3                2 weeks          4.0  \n",
      "4                2 weeks          5.0  \n",
      "\n",
      "Rows with Invalid Dates (checkout <= returned):\n",
      "       Id                Books Book checkout Book Returned  \\\n",
      "0    1.0  Catcher in the Rye     2023-02-20    2023-02-25   \n",
      "5    6.0         Little Women    2023-04-02    2023-05-01   \n",
      "8    9.0             Catch 22    2023-04-15    2023-04-16   \n",
      "9   10.0         Animal Farm     2023-04-20    2023-04-24   \n",
      "10  11.0                 1984    2023-04-23    2023-04-27   \n",
      "\n",
      "   Days allowed to borrow  Customer ID  \n",
      "0                 2 weeks          1.0  \n",
      "5                 2 weeks          1.0  \n",
      "8                 2 weeks          7.0  \n",
      "9                 2 weeks          2.0  \n",
      "10                2 weeks          8.0  \n",
      "\n",
      "Rows with Missing Customer ID (NaN):\n",
      "       Id Books Book checkout Book Returned Days allowed to borrow  Customer ID\n",
      "20  21.0   NaN    2023-06-01    2023-06-05                2 weeks          NaN\n",
      "21   NaN   NaN           NaT           NaT                    NaN          NaN\n",
      "22   NaN   NaN           NaT           NaT                    NaN          NaN\n",
      "23   NaN   NaN           NaT           NaT                    NaN          NaN\n",
      "24   NaN   NaN           NaT           NaT                    NaN          NaN\n"
     ]
    }
   ],
   "source": [
    "# Function to validate that checkout date > returned date\n",
    "def validate_checkout_return_dates(df, checkout_col, returned_col):\n",
    "    # Convert both columns to datetime if not already\n",
    "    df[checkout_col] = pd.to_datetime(df[checkout_col], errors='coerce')\n",
    "    df[returned_col] = pd.to_datetime(df[returned_col], errors='coerce')\n",
    "\n",
    "    # Create DataFrame to store rows where validation fails (checkout <= returned)\n",
    "    invalid_dates = df[df[checkout_col] <= df[returned_col]]\n",
    "    return invalid_dates\n",
    "\n",
    "# Main function to clean and validate data\n",
    "def clean_and_validate_data(df, checkout_col, returned_col, customer_id_col):\n",
    "    # Step 1: Clean and fix the dates in the checkout column\n",
    "    # df[checkout_col] = df[checkout_col].apply(fix_invalid_date)\n",
    "    # df[returned_col] = df[returned_col].apply(fix_invalid_date)\n",
    "\n",
    "    # Step 2: Perform the checkout > returned date validation\n",
    "    invalid_dates = validate_checkout_return_dates(df, checkout_col, returned_col)\n",
    "\n",
    "    # Step 3: Identify rows with NaN Customer ID\n",
    "    df_to_be_checked = df[df[customer_id_col].isna()]\n",
    "\n",
    "    # Step 4: Remove rows with NaN Customer ID from the main DataFrame\n",
    "    df_cleaned = df.dropna(subset=[customer_id_col])\n",
    "\n",
    "    # Step 5: Return cleaned data, rows with invalid dates, and rows with missing customer IDs\n",
    "    return df_cleaned, invalid_dates, df_to_be_checked\n",
    "\n",
    "# Example Usage:\n",
    "# df = pd.read_csv('your_data.csv')  # Load your dataframe\n",
    "\n",
    "# Specify column names\n",
    "checkout_col = 'Book checkout'\n",
    "returned_col = 'Book Returned'\n",
    "customer_id_col = 'Customer ID'\n",
    "\n",
    "# Apply the cleaning and validation function\n",
    "df_cleaned, invalid_dates, df_to_be_checked = clean_and_validate_data(df, checkout_col, returned_col, customer_id_col)\n",
    "\n",
    "# Check the results\n",
    "print(\"Cleaned DataFrame:\\n\", df_cleaned.head())\n",
    "print(\"\\nRows with Invalid Dates (checkout <= returned):\\n\", invalid_dates.head())\n",
    "print(\"\\nRows with Missing Customer ID (NaN):\\n\", df_to_be_checked.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e59dc507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer ID   Customer Name\n",
      "0          1.0        Jane Doe\n",
      "1          2.0      John Smith\n",
      "2          3.0      Dan Reeves\n",
      "3          NaN             NaN\n",
      "4          5.0  William Holden\n"
     ]
    }
   ],
   "source": [
    "file_path2 = '03_Library SystemCustomers.csv'\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df2 = pd.read_csv(file_path2)\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5c94fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nan_customer_id(df):\n",
    "    \"\"\"\n",
    "    Drop rows where 'Customer ID' is NaN from the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: The DataFrame to clean.\n",
    "\n",
    "    Returns:\n",
    "    - A new DataFrame with rows containing NaN in 'Customer ID' removed.\n",
    "    \"\"\"\n",
    "    # Drop rows where 'Customer ID' is NaN\n",
    "    cleaned_df = df.dropna(subset=['Customer ID'])\n",
    "    \n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "53e1f3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer ID   Customer Name\n",
      "0          1.0        Jane Doe\n",
      "1          2.0      John Smith\n",
      "2          3.0      Dan Reeves\n",
      "4          5.0  William Holden\n",
      "5          6.0   Jaztyn Forest\n"
     ]
    }
   ],
   "source": [
    "# Clean the data by removing rows where Customer ID is NaN\n",
    "df2_cleaned = drop_nan_customer_id(df2)\n",
    "\n",
    "# Check the result\n",
    "print(df2_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4cf13a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error connecting to the SQL Server: (pyodbc.InterfaceError) ('IM002', '[IM002] [Microsoft][ODBC Driver Manager] Data source name not found and no default driver specified (0) (SQLDriverConnect)')\n",
      "(Background on this error at: https://sqlalche.me/e/20/rvf5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13932\\2089706335.py:38: SAWarning: No driver name specified; this is expected by PyODBC when using DSN-less connections\n",
      "  engine = create_engine(connection_string)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pyodbc\n",
    "\n",
    "# Connection details\n",
    "server = 'localhost'  # SQL Server address (use localhost if it's on the same machine)\n",
    "database = 'master'  # Connect to the master database first to create the new database\n",
    "\n",
    "# Define the connection string\n",
    "connection_string = (\n",
    "    'mssql+pyodbc:///?'\n",
    "    'Driver=ODBC Driver 17 for SQL Server;'\n",
    "    f'Server={server};'\n",
    "    f'Database={database};'\n",
    "    'Trusted_Connection=yes;'\n",
    ")\n",
    "\n",
    "# Function to create a new database\n",
    "def create_database(engine, db_name):\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            conn.execute(f\"IF NOT EXISTS (SELECT * FROM sys.databases WHERE name = '{db_name}') \"\n",
    "                         f\"BEGIN CREATE DATABASE {db_name} END\")\n",
    "        print(f\"Database '{db_name}' is ready.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating database: {e}\")\n",
    "\n",
    "# Function to upload DataFrames to SQL Server\n",
    "def upload_dataframe_to_sql(df, table_name, engine):\n",
    "    try:\n",
    "        df.to_sql(table_name, con=engine, if_exists='replace', index=False)\n",
    "        print(f\"DataFrame uploaded successfully to '{table_name}' table.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading DataFrame to {table_name}: {e}\")\n",
    "\n",
    "# Try to connect to the SQL Server and create the 'tempdb_qa' database\n",
    "try:\n",
    "    engine = create_engine(connection_string)\n",
    "    \n",
    "    # Check if the connection is successful by executing a simple query\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(\"SELECT 1\")\n",
    "        print(\"Successfully connected to the SQL Server.\")\n",
    "    \n",
    "    # Create the 'tempdb_qa' database if it doesn't exist\n",
    "    create_database(engine, 'tempdb_qa')\n",
    "\n",
    "    # Now, let's connect to the 'tempdb_qa' database\n",
    "    connection_string = (\n",
    "        'mssql+pyodbc:///?'\n",
    "        'Driver=ODBC Driver 17 for SQL Server;'\n",
    "        f'Server={server};'\n",
    "        f'Database=tempdb_qa;'\n",
    "        'Trusted_Connection=yes;'\n",
    "    )\n",
    "    engine = create_engine(connection_string)\n",
    "    \n",
    "    # Sample DataFrames (df and df2) - replace these with your actual DataFrames\n",
    "    df = pd.DataFrame({\n",
    "        'Id': [1, 2, 3],\n",
    "        'Books': ['Book A', 'Book B', 'Book C'],\n",
    "        'Book checkout': ['01/01/2022', '02/01/2022', '03/01/2022'],\n",
    "        'Book Returned': ['05/01/2022', '06/01/2022', '07/01/2022']\n",
    "    })\n",
    "\n",
    "    df2 = pd.DataFrame({\n",
    "        'Customer ID': [101, 102, None],\n",
    "        'Customer Name': ['John Doe', 'Jane Doe', 'Alice Smith']\n",
    "    })\n",
    "\n",
    "    # Upload DataFrames to the SQL Server\n",
    "    upload_dataframe_to_sql(df, 'df_table', engine)\n",
    "    upload_dataframe_to_sql(df2, 'df2_table', engine)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to the SQL Server: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "085fc0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SQL Server', 'SQL Server Native Client RDA 11.0', 'ODBC Driver 17 for SQL Server', 'Microsoft Access Driver (*.mdb, *.accdb)', 'Microsoft Excel Driver (*.xls, *.xlsx, *.xlsm, *.xlsb)', 'Microsoft Access Text Driver (*.txt, *.csv)']\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "print(pyodbc.drivers())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc9bb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload df DataFrame to SQL Server\n",
    "df.to_sql('df_table', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "# Upload df2 DataFrame to SQL Server\n",
    "df2.to_sql('df2_table', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"DataFrames uploaded successfully to tempdb_qa database!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
